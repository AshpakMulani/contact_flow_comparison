{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a9aa5d",
   "metadata": {},
   "source": [
    "# Demo 1 - Customizing OpenAI GPT-3 for Diverse Language Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ab3c4-df7b-46a6-be0c-a70a45b3067d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This lab focuses on demonstrating prompt engineering techniques using Azure OpenAI. Prompt engineering is a critical aspect of utilizing OpenAI models effectively, as it involves crafting prompts that generate desired outputs. In this lab, we will cover various scenarios, including QnA, summarizing text, classifying text, generating new product names, translation, parsing unstructured data, and translating natural language queries into SQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160dc83-b832-470b-bbe5-0813e36636a5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    " - Ensure you have an Azure OpenAI account.\n",
    " - Install the required libraries: `openai` and `python-dotenv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8de6d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.27.8 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.27.8)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: langchain==0.0.330 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.0.330)\n",
      "Requirement already satisfied: langchainhub in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.1.14)\n",
      "Requirement already satisfied: chromadb in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.4.18)\n",
      "Requirement already satisfied: weaviate-client in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.25.3)\n",
      "Requirement already satisfied: azure-search-documents==11.4.0b8 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (11.4.0b8)\n",
      "Requirement already satisfied: azure-identity in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from openai==0.27.8->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from openai==0.27.8->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from openai==0.27.8->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (2.0.23)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (0.0.68)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (1.10.13)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchain==0.0.330->-r requirements.txt (line 3)) (8.2.3)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from azure-search-documents==11.4.0b8->-r requirements.txt (line 7)) (1.29.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from azure-search-documents==11.4.0b8->-r requirements.txt (line 7)) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from azure-search-documents==11.4.0b8->-r requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from langchainhub->-r requirements.txt (line 4)) (2.31.0.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (0.103.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5)) (0.24.0.post1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (4.5.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (1.16.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (1.21.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (0.15.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (1.59.3)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (4.1.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (28.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 5)) (4.0.1)\n",
      "Requirement already satisfied: validators<1.0.0,>=0.21.2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from weaviate-client->-r requirements.txt (line 6)) (0.22.0)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from weaviate-client->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from azure-identity->-r requirements.txt (line 8)) (41.0.7)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from azure-identity->-r requirements.txt (line 8)) (1.25.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from azure-identity->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 1)) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.330->-r requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.330->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.330->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.330->-r requirements.txt (line 3)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.330->-r requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 5)) (0.27.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.330->-r requirements.txt (line 3)) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (2.24.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (1.6.4)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (1.26.18)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity->-r requirements.txt (line 8)) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: coloredlogs in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 5)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 5)) (23.5.26)\n",
      "Requirement already satisfied: packaging in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 5)) (23.2)\n",
      "Requirement already satisfied: protobuf in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 5)) (4.25.1)\n",
      "Requirement already satisfied: sympy in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 5)) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 5)) (6.9.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 5)) (1.61.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 5)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.21.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 5)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.42b0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5)) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.42b0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5)) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5)) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.42b0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5)) (0.42b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5)) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5)) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 5)) (1.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.8->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb->-r requirements.txt (line 5)) (0.19.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 5)) (8.1.7)\n",
      "Requirement already satisfied: types-urllib3 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from types-requests<3.0.0.0,>=2.31.0.2->langchainhub->-r requirements.txt (line 4)) (1.26.25.14)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5)) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5)) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5)) (12.0)\n",
      "Requirement already satisfied: pycparser in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->-r requirements.txt (line 8)) (2.21)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (4.9)\n",
      "Requirement already satisfied: filelock in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 5)) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 5)) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 5)) (3.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.330->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 5)) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/indrajitsingh/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d61902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79f5ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.13 (main, Aug 24 2023, 12:59:26) [Clang 15.0.0 (clang-1500.0.40.1)]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457eb2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version = 0.27.8\n"
     ]
    }
   ],
   "source": [
    "print(\"openai version =\", openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab12be4-515a-4d70-bf1b-fe5e9dbb4523",
   "metadata": {},
   "source": [
    "Create an Azure OpenAI API key and set up your environment variables. Create a file named `azure.env` with the following content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8242afa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d96c1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"genaicourse\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ac1fa",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a33a2",
   "metadata": {},
   "source": [
    "### 1. QnA\n",
    "In this section, we will use Azure OpenAI to answer questions.\n",
    "\n",
    "The primary goal of this section is to showcase how the model can understand and generate meaningful responses based on the given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb89a8de-f3c2-4f97-a5d6-3f5e58f201ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mWhat are the tasks you can help me with?\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can adjust the temperature for more creative or focused outputs\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increase max_tokens for longer responses\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m output_text \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_text)\n",
      "File \u001b[0;32m~/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Course_Materials/GenAi/Lab/GenAi_Lv2_Labs/.venv/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again."
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"What are the tasks you can help me with?\"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=50  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448867c5-e9e7-4300-a55c-17545692192d",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1.  **Prompt Definition:** The variable `prompt` contains the question provided to the model. In this case, the question is \"Who are you?\"\n",
    "    \n",
    "2.  **API Call:** The `openai.Completion.create` function is used to send a request to the OpenAI GPT-3.5 API. It takes parameters such as the engine (model), the prompt (question), temperature, and max_tokens (maximum number of tokens in the response).\n",
    "    \n",
    "3.  **Response Handling:** The API response is stored in the `results` variable, and the generated text is extracted from it using `results[\"choices\"][0][\"text\"]`. The `strip(\"\\n\")` function is used to remove leading and trailing newline characters.\n",
    "    \n",
    "4.  **Output Printing:** The final generated text is printed to the console using `print(results[\"choices\"][0][\"text\"].strip(\"\\n\"))`.\n",
    "    \n",
    "\n",
    "### Purpose\n",
    "\n",
    "-   **Demonstrating Question Understanding:** This section serves to illustrate how the OpenAI GPT-3.5 model can comprehend and respond appropriately to a given question. The model attempts to provide a coherent answer based on its understanding of the input prompt.\n",
    "    \n",
    "-   **Interaction with the Model:** It showcases the basic interaction pattern with the OpenAI API for question and answer tasks, emphasizing the simplicity of the API integration for such scenarios.\n",
    "    \n",
    "-   **User-Specific Applications:** This functionality is valuable for a range of applications, including chatbots, virtual assistants, and information retrieval systems where users can pose questions, and the system generates relevant responses.\n",
    "    \n",
    "-   **Flexibility in Questioning:** The model's ability to handle various types of questions and provide contextually relevant answers highlights its versatility in natural language understanding.\n",
    "    \n",
    "    \n",
    "\n",
    "> ### Note\n",
    "> \n",
    "> Depending on the nature of the prompt and the desired application, additional parameters such as temperature (controls randomness in the model's output) and max_tokens (limits the length of the response) can be adjusted to fine-tune the behavior of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a70a9-5863-4650-a516-ed61df4e3496",
   "metadata": {},
   "source": [
    "Generate text in French based on a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd361b3c-e1b7-4288-a067-f16a637f42b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour! Comment puis-je vous aider aujourd'hui?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Bonjour\"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=50  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ca234-4f05-461b-9b68-09ed8c78fc75",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1.  **Prompt Definition:** The variable `prompt` contains a French greeting, \"Bonjour,\" which translates to \"Hello\" in English.\n",
    "    \n",
    "2.  **API Call:** The `openai.Completion.create` function is used to send a request to the OpenAI GPT-3.5 API. The parameters include:\n",
    "    \n",
    "    -   `engine`: Specifies the model to use (`text-davinci-003` in this case).\n",
    "    -   `prompt`: The input text provided to the model (`\"Bonjour\"` in French).\n",
    "    -   `temperature`: Controls the randomness of the model's output (set to `0` for deterministic responses).\n",
    "    -   `max_tokens`: Limits the length of the generated text to 800 tokens.\n",
    "3.  **Response Handling:** The API response is stored in the `results` variable. The generated text is then extracted using `results[\"choices\"][0][\"text\"]`. The `strip(\"\\n\")` function is used to remove leading and trailing newline characters.\n",
    "    \n",
    "4.  **Output Printing:** The final generated text is printed to the console using `print(results[\"choices\"][0][\"text\"].strip(\"\\n\"))`.\n",
    "    \n",
    "\n",
    "### Purpose\n",
    "\n",
    "-   **Language Translation:** This code snippet demonstrates the model's ability to understand and respond in French. It can be used for language translation tasks where the model takes input in one language and generates corresponding output in another language.\n",
    "    \n",
    "-   **Multilingual Capabilities:** GPT-3.5's multilingual capabilities allow it to handle prompts in various languages, showcasing its versatility in natural language understanding and generation.\n",
    "    \n",
    "-   **User Interface Localization:** In applications with multilingual user interfaces, this capability can be employed to dynamically generate responses in the user's preferred language.\n",
    "    \n",
    "\n",
    "> ### Note\n",
    "> \n",
    "> -   The choice of the `temperature` parameter influences the randomness of the model's responses. A lower temperature value (e.g., 0) produces more deterministic and focused output, while higher values  introduce more randomness.\n",
    ">\n",
    "> -   Adjustments to the `max_tokens` parameter can be made based on the desired length of the generated text. Setting an appropriate value prevents overly long responses.\n",
    ">     \n",
    "> -   This code illustrates how GPT-3.5 can seamlessly handle prompts in different languages, showcasing its potential in internationalization and localization contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399df257",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Summarize Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60206f2a-d80c-4cf7-a573-a937469b860b",
   "metadata": {},
   "source": [
    "Model's ability to summarize a given text into three short bullet points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a97dbc-8703-4d87-821a-348d2e47aadb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Neutron stars are the collapsed cores of massive supergiant stars with a mass of 10-25 solar masses.\n",
      "- They are the smallest and densest stellar objects, excluding black holes and other hypothetical objects.\n",
      "- Neutron stars have a radius of about 10 kilometers and a mass of around 1.4 solar masses.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Summarize below text in 3 short bullet points：\n",
    "\n",
    "            ###\n",
    "            A neutron star is the collapsed core of a massive supergiant star, \n",
    "            which had a total mass of between 10 and 25 solar masses, \n",
    "            possibly more if the star was especially metal-rich.\n",
    "            Neutron stars are the smallest and densest stellar objects, \n",
    "            excluding black holes and hypothetical white holes, quark stars, \n",
    "            and strange stars. Neutron stars have a radius on the order of \n",
    "            10 kilometres (6.2 mi) and a mass of about 1.4 solar masses. \n",
    "            They result from the supernova explosion of a massive star, \n",
    "            combined with gravitational collapse, that compresses the core \n",
    "            past white dwarf star density to that of atomic nuclei.\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=800  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24743ef3-5bd0-4e5a-894a-c56525661e83",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1.  **Prompt Definition:**\n",
    "    \n",
    "    -   The variable `prompt` contains a lengthy text describing neutron stars. The prompt instructs the model to summarize this text into three short bullet points.\n",
    "2.  **API Call:**\n",
    "    \n",
    "    -   The `openai.Completion.create` function is used to send a request to the OpenAI GPT-3.5 API.\n",
    "    -   The `engine` parameter specifies the GPT-3.5 engine or model to be used.\n",
    "    -   The `prompt` parameter provides the input text (description of a neutron star) to the model.\n",
    "    -   The `temperature` parameter is set to 0, indicating that the model's output should be deterministic and focused.\n",
    "    -   The `max_tokens` parameter limits the length of the generated text to 800 tokens.\n",
    "3.  **Response Handling:**\n",
    "    \n",
    "    -   The API response, including the generated text, is stored in the `results` variable.\n",
    "4.  **Output Printing:**\n",
    "    \n",
    "    -   The generated summary text is extracted from the API response using `results[\"choices\"][0][\"text\"].strip(\"\\n\")`.\n",
    "    -   The `strip(\"\\n\")` function removes leading and trailing newline characters.\n",
    "    -   The final result is printed to the console.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "-   **Text Summarization:**\n",
    "    \n",
    "    -   The primary purpose is to showcase the model's ability to condense a longer piece of text into a concise summary, represented as three short bullet points.\n",
    "-   **Information Extraction:**\n",
    "    \n",
    "    -   It demonstrates how the model can extract key information from a given passage and present it in a structured format, which is particularly useful for distilling essential details from large bodies of text.\n",
    "-   **Automation of Summary Generation:**\n",
    "    \n",
    "    -   Developers can use this code as a foundation for automating the process of summarizing documents or articles, streamlining information extraction tasks.\n",
    "-   **Scalable Content Processing:**\n",
    "    \n",
    "    -   This functionality is valuable in scenarios where there is a need to process and summarize large volumes of textual information efficiently.\n",
    "\n",
    "> ### Note\n",
    "> \n",
    "> -   Developers can experiment with different prompts, text lengths, and temperature settings to fine-tune the summarization process based on their specific use case requirements.\n",
    ">     \n",
    "> -   This code snippet illustrates how the OpenAI GPT-3.5 model can be leveraged for content summarization, offering a glimpse into its capabilities in handling natural language understanding and generation  tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988edc7-b4c8-47aa-a9ad-b9fdc7268235",
   "metadata": {},
   "source": [
    "### Chinese Text Summarization\n",
    "\n",
    "The provided code snippet focuses on leveraging the OpenAI GPT-3.5 model to generate a brief summary of a Chinese text. The text in question describes the characteristics of a neutron star, including its mass, size, and the process by which it is formed. The goal is to obtain a concise summary represented in simplified Chinese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5c1b8b-ad07-4e17-af99-65c01baf6bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中子星是一种质量巨大的恒星坍缩核心，质量可达10至25太阳质量。它是宇宙中最小最密集的恒星物体之一，其半径约为10公里，质量约为1.4太阳质量。中子星形成于超新星爆炸和引力坍缩的过程中，使得核心压缩到比白矮星更高的原子核密度。除了中子星，宇宙中还存在黑洞、假想的白洞、夸克星和奇异星等其他类似的天体。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"简要概括下面文字：\n",
    "\n",
    "            ###\n",
    "            中子星是一颗质量达10至25太阳质量（如果恒星特别富含金属可能更多）的超级巨星的坍缩核心。\n",
    "            中子星是最小最密集的恒星物体，除了黑洞和假想的白洞、夸克星和奇异星。\n",
    "            中子星的半径约为10公里（6.2英里），质量约为1.4太阳质量。\n",
    "            它们是由超级新星爆炸和引力坍缩共同产生的，使核心压缩到白矮星密度以上的原子核密度。\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=800  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b37557-9e52-494b-b4eb-968f478fd1ad",
   "metadata": {},
   "source": [
    "\n",
    "#### Explanation\n",
    "\n",
    "1.  **Prompt Definition:**\n",
    "    \n",
    "    -   The variable `prompt` contains a Chinese passage instructing the model to summarize the provided text.\n",
    "2.  **API Call:**\n",
    "    \n",
    "    -   The `openai.Completion.create` function is used to send a request to the OpenAI GPT-3.5 API.\n",
    "    -   The `engine` parameter specifies the GPT-3.5 engine or model to be used.\n",
    "    -   The `prompt` parameter provides the input text (description of a neutron star in Chinese) to the model.\n",
    "    -   The `temperature` parameter is set to 0, indicating that the model's output should be deterministic and focused.\n",
    "    -   The `max_tokens` parameter limits the length of the generated text to 800 tokens.\n",
    "3.  **Response Handling:**\n",
    "    \n",
    "    -   The API response, including the generated summary text, is stored in the `results` variable.\n",
    "4.  **Output Printing:**\n",
    "    \n",
    "    -   The generated summary text is extracted from the API response using `results[\"choices\"][0][\"text\"].strip(\"\\n\")`.\n",
    "    -   The `strip(\"\\n\")` function removes leading and trailing newline characters.\n",
    "    -   The final result is printed to the console.\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "-   **Cross-Language Summarization:**\n",
    "    \n",
    "    -   This code exemplifies the OpenAI GPT-3.5 model's capability to summarize information in a language other than English, showcasing its multilingual text processing capabilities.\n",
    "-   **Automated Content Summarization:**\n",
    "    \n",
    "    -   It illustrates how the model can be used to automate the process of summarizing content in Chinese, providing a concise overview of a given text.\n",
    "-   **Language Understanding and Generation:**\n",
    "    \n",
    "    -   The code demonstrates the model's proficiency in understanding and generating text in a non-English language, extending its utility to a global context.\n",
    "\n",
    "#### Note\n",
    "\n",
    "-   Developers can adapt this code for various applications, such as building multilingual summarization tools or integrating cross-language capabilities into their natural language processing workflows.\n",
    "    \n",
    "-   Adjustments to the prompt, temperature, and other parameters can be made based on specific use case requirements and language nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814896f",
   "metadata": {},
   "source": [
    "### 3. Classify Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f567f-ac44-4cec-bbdb-585522b770d8",
   "metadata": {},
   "source": [
    "`Classify Text` refers to the task of assigning predefined categories or labels to a given piece of text based on its content and context. The goal is to automatically categorize the text into one or more predefined classes, making it easier to organize, search, and analyze large volumes of textual data. This task falls under the broader field of natural language processing (NLP) and is commonly used in various applications, including sentiment analysis, topic categorization, and content filtering.\n",
    "\n",
    "The process typically involves training a machine learning model on a labeled dataset where each text sample is associated with its corresponding category. The model learns patterns and features from the training data, allowing it to generalize and classify new, unseen text accurately.\n",
    "\n",
    "In the context of the provided code snippet, \"Classify Text\" specifically refers to instructing the OpenAI GPT-3.5 model to categorize a news article into one of the specified categories: Tech, Politics, Sport, or Entertainment. The model generates a response that represents its prediction of the most suitable category based on its understanding of the given news article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcd125e-407b-4d97-bd92-e4e8dc3d4e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entertainment\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the following news article into 1 of the following categories: \n",
    "            [Tech, Politics, Sport, Entertainment]\n",
    "\n",
    "            ###\n",
    "            Donna Steffensen Is Cooking Up a New Kind of Perfection. \n",
    "            The Internet’s most beloved cooking guru has a buzzy new book and \n",
    "            a fresh new perspective:\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=800  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6109264-5d7f-4e93-acb8-365e4852e38e",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "1.  **Prompt Definition:**\n",
    "    \n",
    "    -   The `prompt` variable sets the instructions for the model. It instructs the model to classify the provided news article into one of the predefined categories: Tech, Politics, Sport, or Entertainment.\n",
    "2.  **News Article:**\n",
    "    \n",
    "    -   The provided news article is about Donna Steffensen, described as a cooking guru with a new book and a fresh perspective.\n",
    "3.  **API Call:**\n",
    "    \n",
    "    -   The `openai.Completion.create` function sends a request to the OpenAI GPT-3.5 API for text generation.\n",
    "    -   The `engine` parameter specifies the GPT-3.5 engine or model to be used.\n",
    "    -   The `prompt` parameter supplies the input text (news article and classification instruction) to the model.\n",
    "    -   The `temperature` parameter is set to 0, indicating a deterministic response without randomness.\n",
    "    -   The `max_tokens` parameter limits the length of the generated text to 800 tokens.\n",
    "4.  **Response Handling:**\n",
    "    \n",
    "    -   The API response, including the generated text (classification result), is stored in the `results` variable.\n",
    "5.  **Output Printing:**\n",
    "    \n",
    "    -   The generated classification result is extracted from the API response using `results[\"choices\"][0][\"text\"].strip(\"\\n\")`.\n",
    "    -   The `strip(\"\\n\")` function removes leading and trailing newline characters.\n",
    "    -   The final result is printed to the console.\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "-   **Text Classification:**\n",
    "    \n",
    "    -   The code demonstrates the use of the OpenAI GPT-3.5 model for text classification. The model categorizes a given news article into one of the specified classes (Tech, Politics, Sport, or Entertainment).\n",
    "-   **Automated Categorization:**\n",
    "    \n",
    "    -   It showcases the potential for automating the categorization of news articles based on their content, providing a quick and efficient way to organize information.\n",
    "-   **Understanding Context:**\n",
    "    \n",
    "    -   The model's ability to comprehend the context of the news article and assign it to a relevant category highlights its proficiency in understanding natural language and context.\n",
    "\n",
    "#### Note\n",
    "\n",
    "-   Developers can customize the prompt and categories based on their specific use case, expanding the application to various domains that involve text classification.\n",
    "    \n",
    "-   Fine-tuning the parameters, such as temperature, can be explored to influence the randomness and creativity of the generated classification result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127f95b",
   "metadata": {},
   "source": [
    "### 4. Generate New Product Name\n",
    "\n",
    "It automatically create a unique product name based on specified information. With a product description of a \"home milkshake maker\" and seed words like \"fast, healthy, compact,\" the model generates a fitting name inspired by provided examples. This showcases the capability of the model in creative product naming, offering a streamlined and automated approach for inventing distinctive names for various products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68e7324a-e559-42f6-90ce-58f98a92a8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlendFit, RapidShake, NutriShake, SpeedyBlend, MiniShake, SlimShake, TurboShaker, PowerBlend, VitaShake, ShakeExpress\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Generate new product name based on the following information：\n",
    "            \n",
    "            ###\n",
    "            Product description: A home milkshake maker\n",
    "            Seed words: fast, healthy, compact\n",
    "            Product names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=800  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40e666",
   "metadata": {},
   "source": [
    "### 5. Translation\n",
    "\n",
    "In \"Translation\" you translate a Chinese poem into English. The provided poem describes the scenery of mountains, the flow of the Yellow River into the sea, and the desire to explore distant landscapes. The model generates an English translation, showcasing its ability to understand and convert text between different languages. The resulting translation is then printed to the console, demonstrating the model's proficiency in cross-language tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df4f0220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "The white sun sets behind the mountains, the Yellow River flows into the sea.\n",
      "If you desire to see a thousand miles, climb to a higher floor.\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"请用英语翻译下面这首诗歌：\n",
    "            \n",
    "            ###\n",
    "            白日依山尽，黄河入海流。\n",
    "            欲穷千里目，更上一层楼。\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=800  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783da05",
   "metadata": {},
   "source": [
    "### 6. Parse Unstructured Data\n",
    "\n",
    "In \"Parse Unstructured Data\" you process information about fruits on the fictional planet Goocrux. Descriptions of various fruits, such as neoskizzles, loheckles, pounits, loopnovas, and glowls, are provided. The code instructs the model to create a structured table summarizing these fruits, including details like color and flavor. The resulting table is generated by the model and printed to the console, showcasing the model's ability to organize and present information in a tabular format based on unstructured input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d38ed82e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Neoskizzles | Purple | Candy |\n",
      "| Loheckles | Grayish blue | Tart |\n",
      "| Pounits | Bright green | Savory |\n",
      "| Loopnovas | Neon pink | Cotton candy |\n",
      "| Glowls | Pale orange | Sour and bitter |\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"There are many fruits that were found on the recently discovered planet Goocrux. \n",
    "            There are neoskizzles that grow there, which are purple and taste like candy. \n",
    "            There are also loheckles, which are a grayish blue fruit and are very tart, a \n",
    "            little bit like a lemon. Pounits are a bright green color and are more savory \n",
    "            than sweet. There are also plenty of loopnovas which are a neon pink flavor and \n",
    "            taste like cotton candy. Finally, there are fruits called glowls, which have a very\n",
    "            sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\n",
    "            \n",
    "            ###\n",
    "            Please make a table summarizing the fruits from Goocrux\n",
    "            | Fruit | Color | Flavor |\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=800  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b8a78",
   "metadata": {},
   "source": [
    "### 7. NLP to SQL\n",
    "\n",
    "In \"NLP to SQL\" you convert natural language instructions into a SQL query. The provided prompt defines three PostgreSQL tables (Employee, Department, and Salary_Payments) with their respective properties. The code then instructs the model to generate a SQL query for listing the names of departments that employed more than 10 employees in the last 3 months.\n",
    "\n",
    "The resulting SQL query is generated by the model and printed to the console, showcasing the model's ability to understand and convert natural language queries into structured SQL statements for database operations. This code provides an example of how natural language processing can be applied to automate the generation of SQL queries based on human-readable instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80feffef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To list the names of the departments that employed more than 10 employees in the last 3 months, you can use the following SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT d.name AS department_name\n",
      "FROM Department d\n",
      "INNER JOIN Employee e ON d.id = e.department_id\n",
      "INNER JOIN Salary_Payments sp ON e.id = sp.employee_id\n",
      "WHERE sp.date >= NOW() - INTERVAL '3 months'\n",
      "GROUP BY d.name\n",
      "HAVING COUNT(e.id) > 10;\n",
      "```\n",
      "\n",
      "This query joins the `Department`, `Employee`, and `Salary_Payments` tables together using appropriate foreign key relationships. It then filters the results to only include entries where the payment date is within the last 3 months. Finally, it groups the results by department and only includes departments with more than 10 employees.\n",
      "\n",
      "Note that the actual syntax may vary depending on your specific database system.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"### Postgres SQL tables, with their properties:\n",
    "            #\n",
    "            # Employee(id, name, department_id)\n",
    "            # Department(id, name, address)\n",
    "            # Salary_Payments(id, employee_id, amount, date)\n",
    "            #\n",
    "            \n",
    "            ### A query to list the names of the departments \n",
    "                which employed more than 10 employees in the last 3 months\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "results = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,  # You can adjust the temperature for more creative or focused outputs\n",
    "    max_tokens=800  # Increase max_tokens for longer responses\n",
    ")\n",
    "\n",
    "output_text = results[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20daa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
